{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN+I/zfUd0b03tOow7KbqP9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bfestus/medical_chatbot_qa/blob/main/medical_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 1: Setup & Data Preparation"
      ],
      "metadata": {
        "id": "yOkWxp-FRdXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Medical_chatbot/medical_qa_doctor_style_refined.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Clean dataset\n",
        "df.drop_duplicates(inplace=True)\n",
        "df['question'] = df['question'].str.strip()\n",
        "df['answer'] = df['answer'].str.strip()\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Preview\n",
        "print(f\"Total cleaned samples: {len(df)}\")\n",
        "df = df.rename(columns={'question': 'input_text', 'answer': 'target_text'})\n",
        "df['input_text'] = 'healthcare question: ' + df['input_text']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6CvfWOURWL_",
        "outputId": "492beac1-259e-4c89-d40a-dc4c59ba41cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Total cleaned samples: 285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 2: Train/Val/Test Split"
      ],
      "metadata": {
        "id": "krIhKBqeRlT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80-10-10 split\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Datasets\n",
        "from datasets import Dataset, DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': Dataset.from_pandas(train_df),\n",
        "    'validation': Dataset.from_pandas(val_df),\n",
        "    'test': Dataset.from_pandas(test_df)\n",
        "})\n"
      ],
      "metadata": {
        "id": "ViVfLZPNRpGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 3: Tokenization"
      ],
      "metadata": {
        "id": "Zl4n0J6IRs7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "\n",
        "def preprocess(example):\n",
        "    inputs = tokenizer(example['input_text'], max_length=max_input_length, padding=\"max_length\", truncation=True)\n",
        "    targets = tokenizer(example['target_text'], max_length=max_target_length, padding=\"max_length\", truncation=True)\n",
        "    inputs['labels'] = targets['input_ids']\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess, batched=True, remove_columns=dataset['train'].column_names)\n"
      ],
      "metadata": {
        "id": "vKvlVNc2Rv2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 4: Model Setup"
      ],
      "metadata": {
        "id": "Pxnc6CicR3RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, create_optimizer\n",
        "\n",
        "# Load model\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"tf\")\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 8\n",
        "epochs = 30\n",
        "learning_rate = 5e-5\n",
        "num_train_steps = (len(tokenized_datasets['train']) // batch_size) * epochs\n",
        "optimizer, schedule = create_optimizer(init_lr=learning_rate, num_warmup_steps=0, num_train_steps=num_train_steps)\n"
      ],
      "metadata": {
        "id": "QxHthleLR4U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 5: TF Dataset Creation"
      ],
      "metadata": {
        "id": "Dv7TNp1USAQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset_from_hf(dataset, data_collator, batch_size, shuffle=False):\n",
        "    examples = [{\n",
        "        \"input_ids\": example[\"input_ids\"],\n",
        "        \"attention_mask\": example[\"attention_mask\"],\n",
        "        \"labels\": example[\"labels\"]\n",
        "    } for example in dataset]\n",
        "\n",
        "    def data_generator():\n",
        "        indices = list(range(len(examples)))\n",
        "        if shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "        for i in range(0, len(indices), batch_size):\n",
        "            batch = [examples[j] for j in indices[i:i + batch_size]]\n",
        "            collated = data_collator(batch)\n",
        "            yield (\n",
        "                {\"input_ids\": np.array(collated[\"input_ids\"]), \"attention_mask\": np.array(collated[\"attention_mask\"])},\n",
        "                np.array(collated[\"labels\"])\n",
        "            )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        data_generator,\n",
        "        output_signature=(\n",
        "            {\n",
        "                \"input_ids\": tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "                \"attention_mask\": tf.TensorSpec(shape=(None, None), dtype=tf.int32)\n",
        "            },\n",
        "            tf.TensorSpec(shape=(None, None), dtype=tf.int32)\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Build TF datasets\n",
        "tf_train_dataset = create_tf_dataset_from_hf(tokenized_datasets[\"train\"], data_collator, batch_size, shuffle=True)\n",
        "tf_val_dataset = create_tf_dataset_from_hf(tokenized_datasets[\"validation\"], data_collator, batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "peKhVObGSHdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 6: Model Training & Saving"
      ],
      "metadata": {
        "id": "ZThHSswBSMWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train\n",
        "model.compile(optimizer=optimizer)\n",
        "model.fit(tf_train_dataset, validation_data=tf_val_dataset, epochs=epochs)\n",
        "\n",
        "# Save model\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/Medical_chatbot/healthcare-chatbot-model\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model saved to {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68g73xzDSauq",
        "outputId": "496b95f2-8c31-4480-8eec-1bb3fe08b246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 89s 548ms/step - loss: 5.8964 - val_loss: 2.2403\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 4s 152ms/step - loss: 2.1928 - val_loss: 1.4714\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 5s 161ms/step - loss: 1.5327 - val_loss: 0.9013\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 4s 136ms/step - loss: 0.9885 - val_loss: 0.4240\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 4s 128ms/step - loss: 0.6011 - val_loss: 0.2382\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 4s 140ms/step - loss: 0.3976 - val_loss: 0.1600\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 4s 126ms/step - loss: 0.3083 - val_loss: 0.1145\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 3s 117ms/step - loss: 0.2499 - val_loss: 0.0908\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 3s 119ms/step - loss: 0.2132 - val_loss: 0.0756\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 3s 120ms/step - loss: 0.1986 - val_loss: 0.0658\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 3s 117ms/step - loss: 0.1707 - val_loss: 0.0592\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.1614 - val_loss: 0.0554\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.1442 - val_loss: 0.0526\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.1350 - val_loss: 0.0506\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.1274 - val_loss: 0.0495\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 3s 114ms/step - loss: 0.1186 - val_loss: 0.0481\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.1167 - val_loss: 0.0471\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 3s 115ms/step - loss: 0.1107 - val_loss: 0.0456\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 3s 117ms/step - loss: 0.1080 - val_loss: 0.0450\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.1066 - val_loss: 0.0453\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 3s 120ms/step - loss: 0.1023 - val_loss: 0.0454\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 3s 115ms/step - loss: 0.1020 - val_loss: 0.0446\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 3s 115ms/step - loss: 0.1010 - val_loss: 0.0446\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0998 - val_loss: 0.0445\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0996 - val_loss: 0.0440\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 3s 109ms/step - loss: 0.0959 - val_loss: 0.0437\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 3s 113ms/step - loss: 0.0978 - val_loss: 0.0435\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 3s 115ms/step - loss: 0.0992 - val_loss: 0.0435\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 3s 110ms/step - loss: 0.0976 - val_loss: 0.0435\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 3s 112ms/step - loss: 0.0953 - val_loss: 0.0435\n",
            "Model saved to /content/drive/MyDrive/Colab Notebooks/Medical_chatbot/healthcare-chatbot-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 7: Inference Function"
      ],
      "metadata": {
        "id": "_3Ov60RxTyPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keywords for filtering\n",
        "medical_keywords = [\n",
        "    \"symptom\", \"diagnose\", \"treatment\", \"medicine\", \"disease\", \"doctor\",\n",
        "    \"covid\", \"cancer\", \"diabetes\", \"bipolar\", \"stroke\", \"fever\", \"infection\",\n",
        "    \"pain\", \"mental\", \"health\", \"hospital\", \"vaccine\", \"prescription\",\n",
        "    \"disorder\", \"diagnosed\", \"asthma\", \"epilepsy\", \"hypertension\",\n",
        "    \"depression\", \"anxiety\", \"hiv\", \"ibuprofen\", \"lisinopril\", \"side effects\",\n",
        "    \"paracetamol\", \"atorvastatin\", \"metformin\", \"checkup\", \"healthy lifestyle\",\n",
        "    \"symptoms\", \"water\", \"dose\", \"blood pressure\", \"heart\", \"immune\",\n",
        "    \"medication\", \"mental health\", \"therapy\"\n",
        "]\n",
        "\n",
        "def is_medical_question(question):\n",
        "    return any(keyword in question.lower() for keyword in medical_keywords)\n",
        "\n",
        "def generate_answer(question):\n",
        "    if not is_medical_question(question):\n",
        "        return \"‚ùó Sorry, I can only answer healthcare-related questions.\"\n",
        "    input_text = \"healthcare question: \" + question\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"tf\", padding=True, truncation=True).input_ids\n",
        "    output = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Test examples\n",
        "test_questions = [\n",
        "    \"What are the symptoms of stroke?\",\n",
        "    \"Can bipolar disorder be detected early?\",\n",
        "    \"How is COVID-19 diagnosed?\",\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"\\n‚ùì Question: {q}\")\n",
        "    print(f\"üí¨ Answer: {generate_answer(q)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcYHY_UfT06a",
        "outputId": "a101efca-ea39-4ab4-a42e-b944efe22d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ùì Question: What are the symptoms of stroke?\n",
            "üí¨ Answer: Symptoms of stroke include shortness of breath, fatigue. this information is helpful for understanding the condition better. understanding this response helps in gaining deeper insight into the medical condition and encourages timely medical consultation. If you have any concerns or symptoms, it's important to follow up with a healthcare provider for a personalized evaluation. If you have any concerns or symptoms, it's important to follow up with a healthcare provider for a personalized evaluation.\n",
            "\n",
            "‚ùì Question: Can bipolar disorder be detected early?\n",
            "üí¨ Answer: Yes, certainly, early detection of bipolar disorder is possible through questionnaires, ecg. this information is helpful for understanding the condition better. healthcare providers use behavioral assessments, interviews, and family history to evaluate and detect mood disorders at an early stage, potentially preventing more severe episodes. If you have any concerns or symptoms, it's important to follow up with a healthcare provider for a personalized evaluation. If you have any concerns or symptoms, it's important to follow up with a healthcare provider for a personalized evaluation.\n",
            "\n",
            "‚ùì Question: How is COVID-19 diagnosed?\n",
            "üí¨ Answer: Covid-19 is diagnosed using mri scans, ecg. this information is helpful for understanding the condition better. understanding this response helps in gaining deeper insight into the medical condition and encourages timely medical consultation. If you have any concerns or symptoms, it's important to follow up with a healthcare provider for a personalized evaluation. If you have any concerns or symptoms, it's important to follow up with a healthcare provider for a personalized evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "vfynvvlkwPBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import random\n",
        "\n",
        "# Load fine-tuned model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Medical_chatbot/healthcare-chatbot-model\"\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Medical keywords for filtering\n",
        "medical_keywords = [\n",
        "    \"symptom\", \"diagnose\", \"treatment\", \"medicine\", \"disease\", \"doctor\",\n",
        "    \"covid\", \"cancer\", \"diabetes\", \"bipolar\", \"stroke\", \"fever\", \"infection\",\n",
        "    \"pain\", \"mental\", \"health\", \"hospital\", \"vaccine\", \"prescription\"\n",
        "]\n",
        "\n",
        "# Greeting keywords\n",
        "greeting_keywords = [\n",
        "    \"hello\", \"hi\", \"hey\", \"good morning\", \"good afternoon\", \"good evening\",\n",
        "    \"howdy\", \"greetings\", \"what's up\", \"whats up\", \"how are you\", \"sup\"\n",
        "]\n",
        "\n",
        "# Greeting responses\n",
        "greeting_responses = [\n",
        "    \"Hello! üëã I'm your medical assistant. How can I help you with your health questions today?\",\n",
        "    \"Hi there! ü©∫ I'm here to help with any medical or health-related questions you might have.\",\n",
        "    \"Greetings! üòä I'm your healthcare chatbot. Feel free to ask me about symptoms, treatments, or general health information.\",\n",
        "    \"Hello! üè• Nice to meet you! I'm ready to assist with your medical inquiries.\",\n",
        "    \"Hi! üë®‚Äç‚öïÔ∏è I'm your AI medical assistant. What health topic would you like to discuss today?\"\n",
        "]\n",
        "\n",
        "fun_facts = [\n",
        "    \"Did you know? The human brain has around 86 billion neurons!\",\n",
        "    \"Fun fact: Laughing is good for your heart and can reduce stress.\",\n",
        "    \"Tip: Drinking water can improve cognitive performance.\"\n",
        "]\n",
        "\n",
        "def is_greeting(q):\n",
        "    return any(keyword in q.lower() for keyword in greeting_keywords)\n",
        "\n",
        "def is_medical_question(q):\n",
        "    return any(keyword in q.lower() for keyword in medical_keywords)\n",
        "\n",
        "def generate_answer(question):\n",
        "    question_lower = question.lower().strip()\n",
        "\n",
        "    # Handle greetings\n",
        "    if is_greeting(question_lower):\n",
        "        return random.choice(greeting_responses)\n",
        "\n",
        "    # Handle medical questions\n",
        "    if is_medical_question(question_lower):\n",
        "        input_text = \"healthcare question: \" + question\n",
        "        input_ids = tokenizer(input_text, return_tensors=\"tf\", padding=True, truncation=True).input_ids\n",
        "\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=128,\n",
        "            num_beams=4,\n",
        "            temperature=0.7,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        return response[0].upper() + response[1:]  # Capitalize first letter\n",
        "\n",
        "    # Handle non-medical questions\n",
        "    return random.choice(fun_facts) + \"\\n\\nü©∫ Please ask a healthcare-related question or feel free to greet me!\"\n",
        "\n",
        "# Enhanced chatbot function with immediate message display\n",
        "def chatbot_respond(message, history):\n",
        "    if message.strip() == \"\":\n",
        "        return history, \"\"\n",
        "\n",
        "    # Add user message immediately to chat\n",
        "    new_history = history + [(message, \"Thinking...\")]\n",
        "\n",
        "    # Generate response\n",
        "    response = generate_answer(message)\n",
        "\n",
        "    # Update the last entry with actual response\n",
        "    new_history[-1] = (message, response)\n",
        "\n",
        "    return new_history, \"\"\n",
        "\n",
        "# Function for example questions with immediate display\n",
        "def handle_example_question(question, history):\n",
        "    # Add question immediately to chat\n",
        "    new_history = history + [(question, \"Thinking...\")]\n",
        "\n",
        "    # Generate response\n",
        "    response = generate_answer(question)\n",
        "\n",
        "    # Update with actual response\n",
        "    new_history[-1] = (question, response)\n",
        "\n",
        "    return new_history\n",
        "\n",
        "def clear_chat():\n",
        "    return []\n",
        "\n",
        "# Enhanced CSS with medical color scheme\n",
        "medical_css = \"\"\"\n",
        "/* Medical color scheme with professional appearance */\n",
        "body {\n",
        "    background: linear-gradient(135deg, #e8f5e8 0%, #f0f8ff 100%) !important;\n",
        "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;\n",
        "    padding: 20px !important;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    background: linear-gradient(135deg, #e8f5e8 0%, #f0f8ff 100%) !important;\n",
        "    max-width: 1200px !important;\n",
        "    margin: 0 auto !important;\n",
        "    padding: 20px !important;\n",
        "    border-radius: 20px !important;\n",
        "    box-shadow: 0 10px 30px rgba(0,0,0,0.1) !important;\n",
        "}\n",
        "\n",
        "/* Header styling */\n",
        ".markdown h1 {\n",
        "    color: #2c5530 !important;\n",
        "    text-shadow: 2px 2px 4px rgba(0,0,0,0.1) !important;\n",
        "}\n",
        "\n",
        "/* Chat container styling */\n",
        ".chatbot {\n",
        "    background: #ffffff !important;\n",
        "    border: 2px solid #4a90a4 !important;\n",
        "    border-radius: 15px !important;\n",
        "    box-shadow: 0 4px 15px rgba(74, 144, 164, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Chat messages styling - WhatsApp-like */\n",
        ".message.user {\n",
        "    background: #dcf8c6 !important;\n",
        "    border-radius: 18px 18px 4px 18px !important;\n",
        "    margin: 5px 0 !important;\n",
        "    padding: 8px 12px !important;\n",
        "    max-width: 80% !important;\n",
        "    margin-left: auto !important;\n",
        "    border: 1px solid #b7e5a1 !important;\n",
        "    word-wrap: break-word !important;\n",
        "    white-space: normal !important;\n",
        "    overflow-wrap: break-word !important;\n",
        "}\n",
        "\n",
        ".message.bot {\n",
        "    background: #ffffff !important;\n",
        "    border: 1px solid #e0e0e0 !important;\n",
        "    border-radius: 18px 18px 18px 4px !important;\n",
        "    margin: 5px 0 !important;\n",
        "    padding: 8px 12px !important;\n",
        "    max-width: 80% !important;\n",
        "    margin-right: auto !important;\n",
        "    box-shadow: 0 1px 2px rgba(0,0,0,0.1) !important;\n",
        "    word-wrap: break-word !important;\n",
        "    white-space: normal !important;\n",
        "    overflow-wrap: break-word !important;\n",
        "}\n",
        "\n",
        "/* Fix for chat text display */\n",
        ".chatbot .message, .chatbot .message p {\n",
        "    white-space: normal !important;\n",
        "    word-wrap: break-word !important;\n",
        "    overflow-wrap: break-word !important;\n",
        "    word-break: normal !important;\n",
        "    hyphens: none !important;\n",
        "    writing-mode: horizontal-tb !important;\n",
        "    text-orientation: mixed !important;\n",
        "}\n",
        "\n",
        "/* Ensure proper text flow in chat bubbles */\n",
        ".chatbot .wrap {\n",
        "    white-space: normal !important;\n",
        "    word-wrap: break-word !important;\n",
        "}\n",
        "\n",
        ".chatbot .message-wrap {\n",
        "    white-space: normal !important;\n",
        "    word-wrap: break-word !important;\n",
        "    display: block !important;\n",
        "}\n",
        "\n",
        "/* Input field styling */\n",
        ".textbox input {\n",
        "    background: #ffffff !important;\n",
        "    border: 2px solid #4a90a4 !important;\n",
        "    border-radius: 25px !important;\n",
        "    padding: 12px 18px !important;\n",
        "    font-size: 16px !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "}\n",
        "\n",
        ".textbox input:focus {\n",
        "    border-color: #2c5530 !important;\n",
        "    box-shadow: 0 0 10px rgba(44, 85, 48, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Button styling */\n",
        ".btn-primary {\n",
        "    background: linear-gradient(135deg, #4a90a4 0%, #2c5530 100%) !important;\n",
        "    border: none !important;\n",
        "    border-radius: 25px !important;\n",
        "    padding: 12px 24px !important;\n",
        "    color: white !important;\n",
        "    font-weight: bold !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "    box-shadow: 0 4px 10px rgba(74, 144, 164, 0.3) !important;\n",
        "}\n",
        "\n",
        ".btn-primary:hover {\n",
        "    transform: translateY(-2px) !important;\n",
        "    box-shadow: 0 6px 15px rgba(74, 144, 164, 0.4) !important;\n",
        "}\n",
        "\n",
        ".btn-secondary {\n",
        "    background: linear-gradient(135deg, #dc3545 0%, #c82333 100%) !important;\n",
        "    border: none !important;\n",
        "    border-radius: 25px !important;\n",
        "    padding: 12px 24px !important;\n",
        "    color: white !important;\n",
        "    font-weight: bold !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "}\n",
        "\n",
        ".btn-secondary:hover {\n",
        "    transform: translateY(-2px) !important;\n",
        "    box-shadow: 0 6px 15px rgba(220, 53, 69, 0.4) !important;\n",
        "}\n",
        "\n",
        "/* Sidebar buttons */\n",
        ".sidebar-btn {\n",
        "    background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%) !important;\n",
        "    border: 2px solid #4a90a4 !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 10px 15px !important;\n",
        "    margin: 5px 0 !important;\n",
        "    color: #2c5530 !important;\n",
        "    font-weight: 600 !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "}\n",
        "\n",
        ".sidebar-btn:hover {\n",
        "    background: linear-gradient(135deg, #4a90a4 0%, #2c5530 100%) !important;\n",
        "    color: white !important;\n",
        "    transform: translateX(5px) !important;\n",
        "}\n",
        "\n",
        "/* Example question buttons */\n",
        ".example-btn {\n",
        "    background: linear-gradient(135deg, #e3f2fd 0%, #ffffff 100%) !important;\n",
        "    border: 2px solid #4a90a4 !important;\n",
        "    border-radius: 20px !important;\n",
        "    padding: 10px 15px !important;\n",
        "    margin: 5px !important;\n",
        "    color: #2c5530 !important;\n",
        "    font-weight: 500 !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "    cursor: pointer !important;\n",
        "}\n",
        "\n",
        ".example-btn:hover {\n",
        "    background: linear-gradient(135deg, #4a90a4 0%, #2c5530 100%) !important;\n",
        "    color: white !important;\n",
        "    transform: translateY(-2px) !important;\n",
        "    box-shadow: 0 4px 10px rgba(74, 144, 164, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* About section styling */\n",
        ".about-section {\n",
        "    background: rgba(255, 255, 255, 0.9) !important;\n",
        "    border: 2px solid #4a90a4 !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 15px !important;\n",
        "    margin: 10px 0 !important;\n",
        "    box-shadow: 0 2px 8px rgba(74, 144, 164, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Loading animation for \"Thinking...\" */\n",
        "@keyframes pulse {\n",
        "    0% { opacity: 0.6; }\n",
        "    50% { opacity: 1; }\n",
        "    100% { opacity: 0.6; }\n",
        "}\n",
        "\n",
        ".thinking {\n",
        "    animation: pulse 1.5s infinite;\n",
        "    color: #4a90a4 !important;\n",
        "    font-style: italic !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the interface\n",
        "with gr.Blocks(css=medical_css, theme=gr.themes.Soft(primary_hue=\"teal\", secondary_hue=\"green\")) as demo:\n",
        "\n",
        "    # Header\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div style=\"text-align: center; padding: 15px;\">\n",
        "        <h1 style=\"color: #2c5530; font-size: 2em; margin-bottom: 8px;\">üè• Medical Knowledge Chatbot</h1>\n",
        "        <p style=\"color: #4a90a4; font-size: 16px; font-weight: 500;\">\n",
        "            Your AI assistant for understanding <b>health</b> and <b>medicine</b>\n",
        "        </p>\n",
        "        <div style=\"width: 80px; height: 2px; background: linear-gradient(90deg, #4a90a4, #2c5530); margin: 15px auto; border-radius: 2px;\"></div>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Main chat area\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot_ui = gr.Chatbot(\n",
        "                label=\"üí¨ Medical Assistant Chat\",\n",
        "                height=400,\n",
        "                show_copy_button=True,\n",
        "                bubble_full_width=False,\n",
        "                avatar_images=[\"üë§\", \"ü©∫\"]\n",
        "            )\n",
        "\n",
        "            msg = gr.Textbox(\n",
        "                placeholder=\"Type your medical question here and press Enter...\",\n",
        "                label=\"üí¨ Ask Your Question\",\n",
        "                lines=1,\n",
        "                max_lines=2,\n",
        "                container=True\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"üöÄ Send Message\", variant=\"primary\", scale=2)\n",
        "                clear_btn = gr.Button(\"üßπ Clear Chat\", variant=\"secondary\", scale=1)\n",
        "\n",
        "        # Sidebar\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"\"\"\n",
        "            <div class=\"about-section\">\n",
        "                <h3 style=\"color: #2c5530; margin-bottom: 15px;\">üìö Medical Topics</h3>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "\n",
        "            topic_btns = []\n",
        "            topics = [\n",
        "                (\"ü©∫ Symptoms\", \"symptoms\"),\n",
        "                (\"ü¶† Diseases\", \"diseases\"),\n",
        "                (\"üíä Treatments\", \"treatments\"),\n",
        "                (\"üíâ Medications\", \"medications\"),\n",
        "                (\"üß† Mental Health\", \"mental health\")\n",
        "            ]\n",
        "\n",
        "            for topic_name, topic_key in topics:\n",
        "                btn = gr.Button(topic_name, elem_classes=\"sidebar-btn\")\n",
        "                topic_btns.append(btn)\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            <div class=\"about-section\">\n",
        "                <h3 style=\"color: #2c5530; margin-bottom: 10px;\">‚ÑπÔ∏è About</h3>\n",
        "                <p style=\"color: #555; font-size: 14px; line-height: 1.5;\">\n",
        "                    This chatbot uses a fine-tuned <b>T5 model</b> to provide medical information.<br><br>\n",
        "                    <strong>‚ö†Ô∏è Important:</strong> This is for educational purposes only and should not replace professional medical advice.\n",
        "                </p>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "\n",
        "    # Example questions section\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div style=\"text-align: center; margin: 20px 0 15px 0;\">\n",
        "        <h3 style=\"color: #2c5530; font-size: 1.3em;\">üí° Try These Example Questions</h3>\n",
        "        <p style=\"color: #666; margin-bottom: 15px; font-size: 14px;\">Click on any question to get started</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    example_questions = [\n",
        "        \"What are the symptoms of diabetes?\",\n",
        "        \"How is hypertension treated?\",\n",
        "        \"What is bipolar disorder?\",\n",
        "        \"What medicine is used for asthma?\",\n",
        "        \"Is COVID-19 contagious?\"\n",
        "    ]\n",
        "\n",
        "    with gr.Row():\n",
        "        example_btns = []\n",
        "        for question in example_questions:\n",
        "            btn = gr.Button(question, elem_classes=\"example-btn\", size=\"sm\")\n",
        "            example_btns.append(btn)\n",
        "\n",
        "    # Event handlers\n",
        "    def submit_message(message, history):\n",
        "        return chatbot_respond(message, history)\n",
        "\n",
        "    # Handle regular message submission\n",
        "    submit_btn.click(\n",
        "        fn=submit_message,\n",
        "        inputs=[msg, chatbot_ui],\n",
        "        outputs=[chatbot_ui, msg]\n",
        "    )\n",
        "\n",
        "    # Handle Enter key press\n",
        "    msg.submit(\n",
        "        fn=submit_message,\n",
        "        inputs=[msg, chatbot_ui],\n",
        "        outputs=[chatbot_ui, msg]\n",
        "    )\n",
        "\n",
        "    # Handle example question clicks\n",
        "    for i, btn in enumerate(example_btns):\n",
        "        btn.click(\n",
        "            fn=handle_example_question,\n",
        "            inputs=[gr.State(example_questions[i]), chatbot_ui],\n",
        "            outputs=[chatbot_ui]\n",
        "        )\n",
        "\n",
        "    # Handle clear button\n",
        "    clear_btn.click(\n",
        "        fn=clear_chat,\n",
        "        outputs=[chatbot_ui]\n",
        "    )\n",
        "\n",
        "    # Footer\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div style=\"text-align: center; margin-top: 20px; padding: 15px; background: rgba(255,255,255,0.7); border-radius: 15px;\">\n",
        "        <p style=\"color: #666; font-size: 13px;\">\n",
        "            üè• <strong>Medical Knowledge Chatbot</strong> | Powered by AI for Educational Purposes\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "O9Xj-ivwwSPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}